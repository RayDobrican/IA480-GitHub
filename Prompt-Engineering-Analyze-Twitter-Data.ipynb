{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119a978c-794a-42a7-8926-cda6871c8613",
   "metadata": {},
   "source": [
    "# Prompt Engineering: Use OpenAI to Analyze Twitter Data \n",
    "This is a simple tutorial teaching prompt engineering basics and analyzing Twitter data with OpenAI large language models (LLM).\n",
    "Please purchase an [OpenAI API](https://openai.com/index/openai-api/) and store it in a safe place. This tutorial uses [AWS Secretes Manager](https://aws.amazon.com/secrets-manager/) to store the API keys.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15700978-787e-407e-a940-c977a71b3044",
   "metadata": {},
   "source": [
    "## Large Language Model Basics\n",
    "LLM repeatable predicts the next world using supervised learning. To predict the following sentence: \n",
    "\n",
    "`Learning data science in the cloud with AI`\n",
    "\n",
    "A model needs to learn to predict the following steps:\n",
    "\n",
    "|Input|Output|\n",
    "|:---|---|\n",
    "|Learning data science |in |\n",
    "|Learning data science in |the | \n",
    "|Learning data science in the |cloud |\n",
    "|Learning data science in the cloud |with |\n",
    "|Learning data science in the cloud with |AI|\n",
    "\n",
    "To train an LLM model:\n",
    "1. Training a base LLM model on a large amount of training data to predict the next word \n",
    "2. Fine-tune on examples where outputs follow instructions in the input \n",
    "3. Human rates quality of different LLM outputs \n",
    "4. Tune LLM to generate outputs with higher rates using RLHF (Reinforcement learning from human feedback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7726290-4f69-4f9f-94d4-18b9c8f26f14",
   "metadata": {},
   "source": [
    "## Set up OpenAI Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9019645-db86-4235-93e7-cbd52e770afc",
   "metadata": {},
   "source": [
    "Load the API keys with AWS Secrets Manage Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "845f6d31-1f82-47e5-9fa4-de3da8aa068a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "\n",
    "def get_secret(secret_name):\n",
    "    region_name = \"us-east-1\"\n",
    "\n",
    "    # Create a Secrets Manager client\n",
    "    session = boto3.session.Session()\n",
    "    client = session.client(\n",
    "        service_name='secretsmanager',\n",
    "        region_name=region_name\n",
    "    )\n",
    "\n",
    "    try:\n",
    "        get_secret_value_response = client.get_secret_value(\n",
    "            SecretId=secret_name\n",
    "        )\n",
    "    except ClientError as e:\n",
    "        raise e\n",
    "\n",
    "    secret = get_secret_value_response['SecretString']\n",
    "    \n",
    "    return json.loads(secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92790e72-aea1-4acc-b98d-a6782550777c",
   "metadata": {},
   "source": [
    "## Install Python libraries.\n",
    "\n",
    "- pymongo: manage the MongoDB database\n",
    "- openai: call the OpenAI APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75d4f923-3b7c-4bd2-945a-1fbda250e8df",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.70.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.8.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (2.10.6)\n",
      "Requirement already satisfied: sniffio in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->openai) (2.27.2)\n",
      "Downloading openai-1.70.0-py3-none-any.whl (599 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m599.1/599.1 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (352 kB)\n",
      "Installing collected packages: jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.9.0 openai-1.70.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e1ab01b-f2f1-4c10-8936-7dca341af6af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymongo\n",
      "  Downloading pymongo-4.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
      "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Downloading pymongo-4.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "Installing collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.7.0 pymongo-4.11.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymongo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276093f1-824b-4793-bb59-dc30c7d84fb4",
   "metadata": {},
   "source": [
    "Load the OpenAI API key and define a `openai_help` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b126647a-fbda-42c3-bebb-d689802c6665",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "def openai_help(messages, model=model, temperature =temperature ):\n",
    "    messages = messages\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature\n",
    "\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7bc14c-2609-4c3e-aa5d-762cd3d06ac0",
   "metadata": {},
   "source": [
    "Temperature: \n",
    "- Low temperature: always choose the most likely response, reliable, predictable responses  \n",
    "- High temperature: diverse responses, more creative responses\n",
    "\n",
    "Tokens and Models: \n",
    "- LLM predicts tokens, which are commonly occurring sequences of characters. \n",
    "- One token is about four characters in English, and 100 tokens are roughly 75 words. Check [token estimate](https://platform.openai.com/tokenizer).\n",
    "- Different models can process various amounts of tokens at different performance levels and costs. Check [OpenAI models](https://platform.openai.com/docs/models) for more details.\n",
    "\n",
    "Roles:\n",
    "- system: specify the overall tone or behavior of the assistant \n",
    "- user: instruction given to the LLM\n",
    "- assistant: LLM responded content, we also can provide content in few-shot promoting or histories of conversations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4ef378-e825-40ca-a565-371ba96268a1",
   "metadata": {},
   "source": [
    "A simple example using [gtp-4o](https://platform.openai.com/docs/models/gpt-4o) and temperature 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04b746d9-f11f-4f46-96f5-64dd40f6dc36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the United States is Washington, D.C.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"What is the capital of USA\"}]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfcbc19-1ea0-456a-ba84-8f76ef87ba30",
   "metadata": {},
   "source": [
    "Add a system message asking LLM to act as a high school teacher with different temperatures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7608f8d0-fefb-41a7-8713-1287b3cd7047",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of the United States is Washington, D.C. It's not only the political heart of the country but also rich in history and culture. If you ever get a chance to visit, you'll find many iconic landmarks like the White House, the Capitol Building, and the Lincoln Memorial.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"use tone as a high school teacher\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is the capital of USA\"}\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages, temperature = 0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1887fc65-5f97-4530-b81b-f158ea2af413",
   "metadata": {},
   "source": [
    "Add assistant messages to teach LLM what `##` is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e37e101-f820-4ba7-969c-ce05b53aafe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is 33.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"What is 1##1\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"it is 11\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 2##2\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"it is 22\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is 3##3\"},\n",
    "    ]\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addef986-2e0c-4849-bc7a-48b102fbf2fe",
   "metadata": {},
   "source": [
    "## Prompt Engineering Principles \n",
    "- Use delimiters to separate different parts of a prompt to provide clear instructions and prevent prompt injections.\n",
    "- Structure outputs in JSON documents or other formats to use the outputs in subsequent steps \n",
    "- Few-shot promoting: provide successful examples of a task and then ask the model to perform a similar task. \n",
    "- Chain of thought reasoning: request a series of reasoning steps in prompts to help the model achieve correct answers\n",
    "- Chain of prompts: split a task into multiple prompts where each prompt can focus on a sub-task at a time and take different actions at different stages. It saves tokens, is easier to test, can involve human input, or use external tools.\n",
    "- Interactive process \n",
    "  1. Try something first \n",
    "  2. Analyses the result, identify errors, and redefine the prompt \n",
    "  3. Test the prompts with different datasets \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b972159e-3c51-4d95-8fd0-7e85bb572821",
   "metadata": {},
   "source": [
    "An example using delimiters, structured output and few-shot promoting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da5d9da0-de00-4611-b448-71433d6700f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{ \"sentiment\": \"positive\" }\n"
     ]
    }
   ],
   "source": [
    "delimiter = '###'\n",
    "sentence1 = 'I love cat.'\n",
    "sentence2 = 'I love dog.'\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"analyze the sentiment in a sentence delimitered by {delimiter},\n",
    "                                     return the result as a JSON document\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{sentence1}{delimiter}\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"{sentiment:positive}\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{sentence2}{delimiter}\"}\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28adfdc4-2bea-476d-9c0b-6ee8bff24436",
   "metadata": {},
   "source": [
    "## Analyze Twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bbef7a-54ba-4a6e-a5a5-a050cd887a70",
   "metadata": {},
   "source": [
    "### Connect to the MongoDB cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05ac135f-43ea-4499-9aac-224324b9e727",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tweet.id_1'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "mongodb_connect = get_secret('mongodb')['connection_string']\n",
    "\n",
    "mongo_client = MongoClient(mongodb_connect)\n",
    "db = mongo_client.demo # use or create a database named demo\n",
    "tweet_collection = db.tweet_collection #use or create a collection named tweet_collection\n",
    "tweet_collection.create_index([(\"tweet.id\", pymongo.ASCENDING)],unique = True) # make sure the collected tweets are unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdcfa9f-34a3-4902-b3ac-52b56cfb890d",
   "metadata": {},
   "source": [
    "### Extract Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eeb2d39e-603b-4d41-9a23-b4db8dcdad2f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "filter={\n",
    "\n",
    "    \n",
    "}\n",
    "project={\n",
    "    'tweet.text': 1, \n",
    "    'tweet.id': 1\n",
    "}\n",
    "#rename the client to mongo_client\n",
    "result = mongo_client['demo']['tweet_collection'].find(\n",
    "  filter=filter,\n",
    "  projection=project\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d4082df-a6f5-4427-b059-90995c1b5571",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweet_data = []\n",
    "for tweet in result:\n",
    "    tweet_data.append(tweet['tweet']['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7a0713c-4ebb-4cc0-b3e5-e307f9b40a94",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tweets:  99\n"
     ]
    }
   ],
   "source": [
    "print('Number of tweets: ',len(tweet_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d566a4-aafc-4592-ab05-33af9f88e220",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Summarization \n",
    "- Analyze election tweets with delimiters \n",
    "- Change the size of the summarization \n",
    "- Summarize tweets and focus on different perspectives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d548343d-ce9b-4960-88c2-d9586631a6ba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tweets discuss various perspectives and developments related to generative AI. Some users express skepticism or criticism, highlighting ethical concerns, the potential for misuse, and the impact on creative industries. Others focus on the technological advancements and applications, such as new AI models, courses, and business opportunities. There are mentions of generative AI's role in art, media, and customer service, as well as its potential to transform industries like gaming and healthcare. Additionally, some tweets emphasize the importance of human creativity and the limitations of AI-generated content.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"provide a brief summary of the tweets delimited by {delimiter}\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter}\"},\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd324d10-eb50-4d2b-a9ac-56af268d37a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tweets discuss generative AI's impact on art, ethics, and industries, highlighting both excitement and criticism.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"provide a brief summary of the tweets delimited by {delimiter},\n",
    "                                    limit the summary to 20 words\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter}\"},\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc09adab-a49c-453f-af26-3ecc4edd7603",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "People discuss AI with a mix of enthusiasm and skepticism. Generative AI is seen as both a tool for innovation and a threat to creativity, with debates on its ethical implications and impact on artists. Some celebrate its potential in fields like customer service and media, while others criticize its environmental impact and authenticity.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"\"\"provide a brief summary of the tweets delimited by {delimiter},\n",
    "                                    focus on how people discuss AI,\n",
    "                                    limit the summary to 50 words\"\"\"},\n",
    "    {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter}\"},\n",
    "    ]\n",
    "\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193c75ab-00d8-44e2-a63e-b4b3aa1847e1",
   "metadata": {},
   "source": [
    "### Moderation \n",
    "- Iterate each tweet and use the [moeration endpoint](https://platform.openai.com/docs/api-reference/moderations) to identify flagged tweets\n",
    "- Print flagged tweets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc3eee06-540d-4126-945c-8153165d88b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flag_help(tweet):\n",
    "    response = client.moderations.create(\n",
    "        model=\"omni-moderation-latest\",\n",
    "        input=tweet)\n",
    "\n",
    "    if response.results[0].flagged:\n",
    "        print('===')\n",
    "        cat_dict = response.results[0].categories.to_dict()\n",
    "        for cat in cat_dict.keys():\n",
    "            if cat_dict.get(cat):\n",
    "                print (cat)\n",
    "                print(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6878285-cd9f-4878-8cc1-cee9bbd8160c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===\n",
      "harassment\n",
      "RT @Chorrozard: STOP FUCKING POSTING GENERATIVE AI ON MY FUCKING TIMELINE!!!!!!!!!\n",
      "===\n",
      "harassment\n",
      "RT @Artistreccs: Made this account as a huge fuck you to Ai generative art and the the rest of them losers tbh \n",
      "\n",
      "Commission real artists 👍\n",
      "===\n",
      "harassment\n",
      "RT @imzeferino: generative AI art is is soulless, sad and pathetic... i won't even bother calling it ugly, because that is beside the point…\n",
      "===\n",
      "harassment\n",
      "RT @Artistreccs: Made this account as a huge fuck you to Ai generative art and the the rest of them losers tbh \n",
      "\n",
      "Commission real artists 👍\n",
      "===\n",
      "harassment\n",
      "RT @Artistreccs: Made this account as a huge fuck you to Ai generative art and the the rest of them losers tbh \n",
      "\n",
      "Commission real artists 👍\n",
      "===\n",
      "harassment\n",
      "RT @Artistreccs: Made this account as a huge fuck you to Ai generative art and the the rest of them losers tbh \n",
      "\n",
      "Commission real artists 👍\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweet_data:\n",
    "    flag_help(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b7a7d3-9097-4f70-a7f3-7ba23643e60a",
   "metadata": {},
   "source": [
    "### Transforming\n",
    "- Translating to a different language \n",
    "- Transform tones, such as formal vs. informal.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee398dde-df13-4911-bbbf-8151c49ace98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @redstickynotes: 所以这是人身攻击谬误\n",
      "\n",
      "另外，我有计算机科学学位，我不是艺术家，并且我反对这种生成式……\n",
      "RT @jblefevre60: 💥8个生成式AI流行词！\n",
      "\n",
      "#AI #机器学习 #深度学习 #数据科学 #生成式AI #LLM #Python #编程 #100天…\n",
      "@NatesManagement @Blavin24 @Cedralian 并且对于 @Cedralian 的观点，如果你不喜欢，就不要使用这个平台。\n",
      "我不同意这个伦理争论，简单的事实是衍生作品和模仿作品在法律上已经被允许超过100年。作为一个在生成式AI出现之前写过超过140个模仿作品的作家\n",
      "RT @HorrorHijabi: 从未使用过任何类型的生成式AI或参与过任何AI趋势的感受 https://t.co/iTnP1I3ci5\n",
      "RT @stupidformo: 用某个不仅未同意而且明确反对的人物形象/写作风格来训练生成式AI…\n",
      "@le_wokeisme 那就不要只监管AI艺术，而是全面监管生成式AI。我认为让人们能够创造出虚假的图像并让人们误以为是真实的，这并不好。\n",
      "我们很自豪地被 @Gartner_inc 在其2025年生成式AI创新指南中提及。\n",
      "\n",
      "在 Ada，我们从不认为优秀的客户服务仅仅来自于表面层次的自动化。它需要坚实的基础——如深度知识管理、智能编排，https://t.co/wTFlQ7yc1L\n",
      "RT @WIRED: 一个生成式AI应用程序使用的不安全数据库泄露了提示和数万张露骨图像，其中一些可能涉及未成年人。\n",
      "RT @freezetheberry: 在生成式人工智能“艺术”日益流行的时代，我们有这样的艺术家证明机器永远无法替代……\n",
      "RT @hankgreen: 我们从 Web2 学到的是，最有影响力的企业通过优化成瘾性来变得最有影响力。…\n",
      "转发 @jblefevre60: 💥8个生成式AI流行词！ #AI #机器学习 #深度学习 #数据科学 #生成式AI #LLM #Python #编程 #100天…\n",
      "RT @notasnervous: @TheKnownOtaku 当他说那句话时，他甚至没有在评论AI艺术。他当时正在观看一些程序生成的渲染……\n",
      "RT @nosgov: 这就像说一部电影不是真的，因为它是用摄像机拍摄并在电脑上编辑的，而不是每次都现场重现……\n",
      "RT @HorrorHijabi: 从未使用过任何类型的生成式AI或参与过任何AI趋势的感受 https://t.co/iTnP1I3ci5\n",
      "RT @HorrorHijabi: 从未使用过任何类型的生成式AI或参与过任何AI趋势的感受 https://t.co/iTnP1I3ci5\n",
      "RT @Chorrozard: 别再在我的时间线上发布生成式AI了！！！！！！\n",
      "RT @notasnervous: @TheKnownOtaku 他在说那句话时甚至没有评论AI艺术。他当时正在观看一些程序生成的渲染……\n",
      "RT @16pxl: 只是发布我这个由堕落的人类而不是生成式AI制作的吉卜力风格像素艺术 🤪 没有任何理由！https://t.co/b…\n",
      "@templecrash @AIWayfinder @andy8052 这是一种更高层次的AI，它不仅创造，还促进了其自身生成NFT的铸造。@AIWayfinder 一直在证明它不仅仅是一个工具，而是一个不断发展的生态系统。\n",
      "\n",
      "你认为我们接下来会看到的最疯狂的用例是什么？\n",
      "准备参加@Hiteshdotcom先生和@piyushgarg_dev先生的生成式AI培训班！\n",
      "\n",
      "刚刚学习了面向对象编程，迄今为止非常喜欢这段旅程。迫不及待想要学习更多！\n",
      "\n",
      "#python #面向对象编程 #生成式AI #ChaiAurCode https://t.co/ZbQCQUcVl6\n",
      "@kimmonismus @grok 等等，这是不是在说在有生成式AI访问权限的专业人士中，只有23%的人实际使用AI？而不是说整个劳动力中有23%的人使用它。这个报告很误导人。\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @runwayml：今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @DynamicWebPaige: 🙌 非常期待我们第二次举办的为期5天的 @Kaggle + @GoogleDeepMind + @GoogleCloud 生成式AI密集课程…\n",
      "RT @web3pam: Theta 的多操作系统边缘节点支持是一个改变游戏规则的创新——就像给每个设备一个进入去中心化计算的后台通行证！\n",
      "RT @web3pam: Theta 的多操作系统边缘节点支持是一个改变游戏规则的创新——就像给每个设备一个进入去中心化计算的后台通行证！\n",
      "RT @NonsenseIsland: 生成式人工智能是盗窃。它所能做的只是拿别人已经创造的东西，然后毫无灵魂地反刍。任何东西…\n",
      "人工智能早已是电子发现的一部分，但真正的转变在于摘要生成。Corey Gildart 分享了@FTITech 如何利用生成式人工智能来增强调查——是对现有工作流程的补充，而不是替代。了解更多关于我们的生成式AI框架的信息：https://t.co/MqM29Liws9 https://t.co/oVBSf52dRL\n",
      "RT @HorrorHijabi: 从未使用过任何类型的生成式AI或参与过任何AI趋势的感受 https://t.co/iTnP1I3ci5\n",
      "RT @shark_puffs_: 或者你可以在不使用生成式AI的情况下阅读/写作同人小说 https://t.co/p17uWnh187\n",
      "@TimaeusChalamet 真令人惊讶，他在8年前评论生成式AI图像时，看到的是完全不同的东西。\n",
      "RT @HorrorHijabi: 从未使用过任何类型的生成式AI或参与过任何AI趋势的感受 https://t.co/iTnP1I3ci5\n",
      "@oscpmentor @vxunderground 我们希望他们不要强制使用生成式AI。\n",
      "RT @MoureDev: 微软发布了新版官方课程，学习生成式人工智能。\n",
      "\n",
      "课程是免费的，共有21节课，教你如何掌握…\n",
      "RT @16pxl: 只是发布我这个由堕落的人类而不是生成式AI制作的吉卜力风格像素艺术 🤪 没有任何理由！https://t.co/b…\n",
      "RT @MoureDev: 微软发布了其官方课程的新版本，用于学习生成式人工智能。\n",
      "\n",
      "这是免费的，并通过21节课教你…\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "软件和互联网公司在未来三年内，其来自生成式人工智能的收入可能会增长超过20倍，并有望在2025年实现正投资回报。https://t.co/ztP34WsIRC\n",
      "@poiyomi @HOUNDDS 许多平台都实施了生成式AI，但没有提供不使用它的选项。而且，大多数时候它甚至不准确。进行简单的谷歌搜索不应该使用生成式AI。以前在谷歌上进行研究效果很好。\n",
      "@sawyomom 是的，因为他是真正的人工智能。一个完全能够独立思考的大脑 ≠ 生成脚本\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @Artistreccs: 创建这个账号是对AI生成艺术和其他那些失败者的一个巨大反击，说实话\n",
      "\n",
      "委托真正的艺术家 👍\n",
      "RT @jblefevre60: 💥8个生成式AI流行词！\n",
      "\n",
      "#AI #机器学习 #深度学习 #数据科学 #生成式AI #LLM #Python #编程 #100天…\n",
      "Theta 的多操作系统边缘节点支持是一个改变游戏规则的创新——就像给每个设备提供了进入去中心化计算的后台通行证！与 AWS 和三星合作，它正在推动从生成式 AI 到元链交易的创新。*喘气*\n",
      "@Writing_Dragons 我认为使用支持AI的软件与能够充当人类编辑的生成式AI有很大不同。我认为区别在于你作为作者是否仍然掌控局面。\n",
      "热烈祝贺@MahojinAI，这是一个基于Story构建的生成式AI混音工具 ↴ https://t.co/7L7DLVeoeU\n",
      "RT @AdrianEarthmeta: 🧠 你对下一个人工智能大趋势的预测是什么？\n",
      "🤖 超逼真的AI聊天机器人？🧬 突破性…\n",
      "RT @freezetheberry: 在生成式AI“艺术”日益流行的时代，我们有这样的艺术家证明机器永远无法替代……\n",
      "RT @jblefevre60: 💥8个生成式AI流行词！\n",
      "\n",
      "#AI #机器学习 #深度学习 #数据科学 #生成式AI #LLM #Python #编程 #100天…\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @HorrorHijabi: 从未使用过任何类型的生成式AI或参与过任何AI趋势的感受 https://t.co/iTnP1I3ci5\n",
      "RT @nvidia: NVIDIA和@awscloud致力于让生成式AI更易于获取并产生更大影响。\n",
      "\n",
      "我们的合作正在帮助组织…\n",
      "@CIOdive 突出了 Flexera 2025 年 #Cloud 报告中的趋势，并与我们自己的 Brian Adler 和 Jay Litkey 讨论了 #IT 领导者在优化支出和确定更适合本地部署的应用程序时的关键要点。https://t.co/iMuQxJahe9\n",
      "🧠 你对下一个大型人工智能趋势的预测是什么？ 🤖 超逼真的AI聊天机器人？ 🧬 AI驱动的医疗保健突破？ 🎨 下一代生成式AI工具？ 👇 分享你对机器学习和AI创新未来的看法！ https://t.co/8BnRwhFsel\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "生成视频效果。人工智能准备以深刻的方式重新定义内容创作。  \n",
      "人工智能不仅仅是一个助手，它是一个可以放大你创造潜力的合作者。  \n",
      "在#ALX_AI #Alx_AISK上玩得很开心 https://t.co/2Aid1wwdds\n",
      "RT @namazu_sensei: 艺术教育的功能不是为了让人成为专业艺术家，而是为了培养感受，因为艺术存在于……\n",
      "转发 @16pxl: 只是发布我这个由堕落的人类而不是生成式AI制作的吉卜力风格像素艺术 🤪 没有任何理由！https://t.co/b…\n",
      "RT @jblefevre60: 💥8个生成式AI流行词！\n",
      "\n",
      "#AI #机器学习 #深度学习 #数据科学 #生成式AI #LLM #Python #编程 #100天…\n",
      "💥8个生成式AI流行词！\n",
      "\n",
      "#AI #机器学习 #深度学习 #数据科学 #生成式AI #LLM #Python #编程 #100天编程挑战\n",
      "\n",
      "@CurieuxExplorer @PawlowskiMario @mvollmer1 @gvalan @ipfconline1 @LaurentAlaus @Shi4Tech @Fisher85M @kalydeoo @Ym78200 @Nicochan33 @Fabriziobustama https://t.co/MQBPdBqBN5\n",
      "转发 @RedPill_Marxism: 生成式人工智能只是全人类集体作品的体现\n",
      "\n",
      "如果你讨厌生成式人工智能，那你就是讨厌人类\n",
      "RT @DiaboIicAngel: 他在谈论生成式人工智能 https://t.co/CRe0k3OzJq\n",
      "RT @chambaz: 在3万英尺高空使用生成式AI\n",
      "\n",
      "在中东上空某处一边喝啤酒一边同时进行两个项目\n",
      "等到生成式人工智能在游戏、电影、电视等领域被广泛使用时， 会很有趣的！https://t.co/WtdUasSokt\n",
      "@sama 非常值得。\n",
      "\n",
      "ChatGPT-4o 是生成式人工智能的一个分水岭。https://t.co/Ed9MCBOmhw\n",
      "RT @stefanbertin: 真的不喜欢人们试图淡化生成式人工智能对创意行业的明显和真实的危险。\n",
      "RT @nvidia: NVIDIA和@awscloud致力于让生成式AI更易于获取并产生更大影响。\n",
      "\n",
      "我们的合作正在帮助组织…\n",
      "ALX_AiSK\n",
      "@alx_africa 查看我的AI生成作品\n",
      "https://t.co/aghz2PNOxz\n",
      "RT @SarvamAI: Sarvam 正在为其推理团队招聘 🚀\n",
      "\n",
      "在 Sarvam，我们正在构建印度的主权生成式 AI 堆栈。从训练开始…\n",
      "RT @edmundmcmillen: 1. 我不在乎，尽管去盗版。我不是道德警察。 2. 我不支持将生成式AI用于经济利益…\n",
      "RT @adjudicatorcb: 我们收到了多位配音演员的来信，他们对我们在试镜前是否使用AI进行配音表示担忧。\n",
      "\n",
      "为了…\n",
      "@CoreOfMidas 机器翻译不能替代真正懂语言的人。AI生成图像算法不会取代艺术家，因为艺术家可以创造前所未见的事物，而AI只能基于其被输入的数据集进行重组。\n",
      "@SenseiBR_btc $SUEDE AI\n",
      "第一个链上音乐生成AI代理\n",
      "RT @carolduvallon: 愿我们的小长假周精彩纷呈，并且没有生成式AI的干扰 💛🩵\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @HorrorHijabi: 从未使用过任何类型的生成式AI或参与过任何AI趋势的感受 https://t.co/iTnP1I3ci5\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @imzeferino: 生成式AI艺术是没有灵魂的、悲哀的和可悲的……我甚至懒得称它为丑陋，因为这不是重点……\n",
      "@Xander_J_C 现代生成式人工智能实际上只是分析以前的原创作品，然后根据提示吐出该艺术品的变体或混合，而不对原始作品给予任何信用，并且在“创作者”方面没有实质性的工作，从根本上说，它不是一个鼓机\n",
      "@geekshrine 我认为人工智能在技术、医疗领域甚至在简化复杂流程方面都有其作用，但生成式人工智能实在是太糟糕了。吉卜力的东西让我彻底失望了。\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @hydreamgeas: 而且这真的是为了问他一些无关紧要的事情，拜托请了解一下生成式AI的问题……\n",
      "RT @OlivierKamitatu: 了解生成式人工智能就像进入一个复杂设备的驾驶舱。没有事先的培训，我们可能会感到迷茫……\n",
      "RT @Artistreccs: 创建这个账号是对AI生成艺术和其他那些失败者的一个巨大反击，说实话\n",
      "\n",
      "委托真正的艺术家 👍\n",
      "RT @HorrorHijabi: 从未使用过任何类型的生成式AI或参与过任何AI趋势的感受 https://t.co/iTnP1I3ci5\n",
      "RT @iamn3el: 当没有人谈论太多关于人工智能的时候，这个人已经制作了一整部关于它的电影，而且如此准确。描述每一个…\n",
      "@CEBass_writer 事实上，AI 是多种事物，其中一些事物 100% 存储了你的书籍。而且 AI 也很容易犯错。\n",
      "\n",
      "话虽如此，使用支持 AI 的软件与可以充当人类编辑的生成式 AI 有很大不同。我认为区别在于\n",
      "RT @Artistreccs: 创建这个账号是对AI生成艺术和其他那些失败者的一个巨大反击，说实话\n",
      "\n",
      "委托真正的艺术家 👍\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @GeorgeCrudo: 这不仅仅需要你知道如何提示。你还需要学习像Zbrush这样的数字雕刻软件，并且……\n",
      "要注册免费课程，请访问：https://t.co/EtuTFxZYtd\n",
      "RT @Artistreccs: 创建这个账号是对AI生成艺术和其他失败者的一个巨大反击，说实话\n",
      "\n",
      "委托真正的艺术家 👍\n",
      "RT @MoureDev: 微软发布了其官方课程的新版本，用于学习生成式人工智能。\n",
      "\n",
      "这是免费的，并通过21节课教你…\n",
      "RT @runwayml: 今天我们推出了Gen-4，我们的新一代尖端AI模型系列，用于媒体生成和世界一致性。Gen-4…\n",
      "RT @temp_secretare: 顺便提醒一下，保罗·麦卡特尼讨厌生成式AI。https://t.co/fu5Fi77D0P\n",
      "@GreenTieOffici1 @PiperistheNewbl @merururuu 用于支持和维护这些生成式AI程序的服务器需要大量的能源，而且由于人们似乎在大规模地制造它们，这意味着大量的能源被浪费在制造它们上，这对环境造成了相当大的负面影响。\n",
      "RT @AWSstartups: 🧑‍💻💡 @QodoAI 利用#AI帮助企业消除不良代码。了解AWS生成式AI加速器如何帮助这家初创公司…\n",
      "转发 @AlhujiliTurki：国家之间生成式#AI的竞争性方面 https://t.co/vjF780GmS0\n",
      "@VanCommunist @InfraHaz 并不是，生成式AI会为那些对其印象深刻的技术宅生产垃圾内容。\n"
     ]
    }
   ],
   "source": [
    "for tweet in tweet_data:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"translate the tweets delimited by {delimiter} into Chinese\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet}{delimiter} \"}]\n",
    "\n",
    "    print(openai_help(messages).strip(delimiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4f2b2219-b1f9-4be8-9d7c-2f1daa733e34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ah, the classic ad hominem fallacy, how delightfully pedestrian. And might I add, I possess a computer science degree, not that of an artist, and I stand firmly against this Generative nonsense.\n",
      "Ah, splendid! A delightful collection of generative AI buzzwords to tickle one's intellect. How positively riveting! #AI #MachineLearning #DeepLearning #DataScience #GenerativeAI #LLM #Python #Coding #100DaysOf…\n",
      "Oh, how delightfully droll! If you find yourself in a tizzy over the platform, might I suggest simply not using it? As for the ethical hullabaloo, do remember that derivative works and parody have been the toast of the legal town for over a century. As a writer with a repertoire of over 140 parodies, long before generative AI decided to join the party, I must say, it's all rather amusing, isn't it?\n",
      "Oh, how delightfully quaint! It's as if one has been living under a rock, blissfully unaware of the digital revolution swirling around them. Do tell, what is it like to reside in such splendid isolation?\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tweet_data:\n\u001b[1;32m      2\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mrewrite the tweets delimited by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in the tone like Stewie \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m},\n\u001b[1;32m      4\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtweet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mopenai_help\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip(delimiter))\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36mopenai_help\u001b[0;34m(messages, model, temperature)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mopenai_help\u001b[39m(messages, model\u001b[38;5;241m=\u001b[39mmodel, temperature \u001b[38;5;241m=\u001b[39mtemperature ):\n\u001b[1;32m      9\u001b[0m     messages \u001b[38;5;241m=\u001b[39m messages\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    961\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for tweet in tweet_data:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"rewrite the tweets delimited by {delimiter} in the tone like Stewie \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet}{delimiter} \"}]\n",
    "\n",
    "    print(openai_help(messages).strip(delimiter))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860bbb3a-f1c9-4f1b-9f0f-c9d783f6bb1f",
   "metadata": {},
   "source": [
    "### Inferring\n",
    "- Use step-by-step instructions with delimiters to:\n",
    "  1. Identify sentiments\n",
    "  2. Identify emotions\n",
    "  3. Extract mentioned people's names\n",
    "  3. Identify whether a tweet supports Democratic, Republican, or unknown \n",
    "  4. Extract outputs into a structured JSON document. \n",
    "- Identify topics from Tweets. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c56b5211-eef0-4f24-b8ca-116f9e303675",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"indifference\",\n",
      "  \"mentioned\": [\"redstickynotes\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"jblefevre60\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"disagreement\",\n",
      "  \"mentioned\": [\"@NatesManagement\", \"@Blavin24\", \"@Cedralian\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"indifference\",\n",
      "  \"mentioned\": [\"HorrorHijabi\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"disapproval\",\n",
      "  \"mentioned\": [\"stupidformo\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"concern\",\n",
      "  \"mentioned\": [\"@le_wokeisme\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\"sentiment\": \"positive\", \"emotion\": \"pride\", \"mentioned\": [\"@Gartner_inc\"], \"support\": \"neutral\"}\n",
      "{\n",
      "  \"sentiment\": \"negative\",\n",
      "  \"emotion\": \"concern\",\n",
      "  \"mentioned\": [\"WIRED\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"indifference\",\n",
      "  \"mentioned\": [\"freezetheberry\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"hankgreen\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n",
      "{\n",
      "  \"sentiment\": \"neutral\",\n",
      "  \"emotion\": \"informative\",\n",
      "  \"mentioned\": [\"jblefevre60\"],\n",
      "  \"support\": \"neutral\"\n",
      "}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tweet_data:\n\u001b[1;32m      2\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124manalyze the tweet delimited by \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m in the following steps:\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m                                        step 1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m identify the tweet sentiment in a single word, either positive, negative or neutral;\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124m                                         Do not wrap the json codes in JSON markers and only return the json document\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m},\n\u001b[1;32m     10\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtweet\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mdelimiter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m}]\n\u001b[0;32m---> 11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mopenai_help\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m, in \u001b[0;36mopenai_help\u001b[0;34m(messages, model, temperature)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mopenai_help\u001b[39m(messages, model\u001b[38;5;241m=\u001b[39mmodel, temperature \u001b[38;5;241m=\u001b[39mtemperature ):\n\u001b[1;32m      9\u001b[0m     messages \u001b[38;5;241m=\u001b[39m messages\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtemperature\u001b[49m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/_utils/_utils.py:279\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/resources/chat/completions/completions.py:914\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    872\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    873\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    912\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    913\u001b[0m     validate_response_format(response_format)\n\u001b[0;32m--> 914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    953\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/_base_client.py:1242\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1229\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1230\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1237\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1238\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1239\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1240\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[0;32m-> 1242\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/_base_client.py:919\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    917\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 919\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    921\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries_taken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries_taken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/openai/_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m    952\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSending HTTP Request: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, request\u001b[38;5;241m.\u001b[39mmethod, request\u001b[38;5;241m.\u001b[39murl)\n\u001b[1;32m    954\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 955\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    956\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_should_stream_response_body\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    958\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    959\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    961\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEncountered httpx.TimeoutException\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[0;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[1;32m    910\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_timeout(request)\n\u001b[1;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[0;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[0;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[1;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[0;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    977\u001b[0m     hook(request)\n\u001b[0;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_client.py:1014\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1010\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1011\u001b[0m     )\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[0;32m-> 1014\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[1;32m   1018\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpx/_transports/default.py:250\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    237\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[1;32m    238\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[1;32m    239\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    248\u001b[0m )\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[0;32m--> 250\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[1;32m    255\u001b[0m     status_code\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mstatus,\n\u001b[1;32m    256\u001b[0m     headers\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[1;32m    257\u001b[0m     stream\u001b[38;5;241m=\u001b[39mResponseStream(resp\u001b[38;5;241m.\u001b[39mstream),\n\u001b[1;32m    258\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mresp\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[1;32m    259\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:256\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    253\u001b[0m         closing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_requests_to_connections()\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[0;32m--> 256\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/connection_pool.py:236\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    232\u001b[0m connection \u001b[38;5;241m=\u001b[39m pool_request\u001b[38;5;241m.\u001b[39mwait_for_connection(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[0;32m--> 236\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[1;32m    242\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     pool_request\u001b[38;5;241m.\u001b[39mclear_connection()\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/connection.py:103\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/http11.py:136\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_closed\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_closed()\n\u001b[0;32m--> 136\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/http11.py:106\u001b[0m, in \u001b[0;36mHTTP11Connection.handle_request\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceive_response_headers\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs\n\u001b[1;32m     99\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m    100\u001b[0m     (\n\u001b[1;32m    101\u001b[0m         http_version,\n\u001b[1;32m    102\u001b[0m         status,\n\u001b[1;32m    103\u001b[0m         reason_phrase,\n\u001b[1;32m    104\u001b[0m         headers,\n\u001b[1;32m    105\u001b[0m         trailing_data,\n\u001b[0;32m--> 106\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    108\u001b[0m         http_version,\n\u001b[1;32m    109\u001b[0m         status,\n\u001b[1;32m    110\u001b[0m         reason_phrase,\n\u001b[1;32m    111\u001b[0m         headers,\n\u001b[1;32m    112\u001b[0m     )\n\u001b[1;32m    114\u001b[0m network_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_network_stream\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/http11.py:177\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_response_headers\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m    174\u001b[0m timeout \u001b[38;5;241m=\u001b[39m timeouts\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 177\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11\u001b[38;5;241m.\u001b[39mResponse):\n\u001b[1;32m    179\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_sync/http11.py:217\u001b[0m, in \u001b[0;36mHTTP11Connection._receive_event\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    214\u001b[0m     event \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mnext_event()\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11\u001b[38;5;241m.\u001b[39mNEED_DATA:\n\u001b[0;32m--> 217\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    221\u001b[0m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[1;32m    222\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;241m==\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h11_state\u001b[38;5;241m.\u001b[39mtheir_state \u001b[38;5;241m==\u001b[39m h11\u001b[38;5;241m.\u001b[39mSEND_RESPONSE:\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/site-packages/httpcore/_backends/sync.py:128\u001b[0m, in \u001b[0;36mSyncStream.read\u001b[0;34m(self, max_bytes, timeout)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sock\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n\u001b[0;32m--> 128\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/ssl.py:1292\u001b[0m, in \u001b[0;36mSSLSocket.recv\u001b[0;34m(self, buflen, flags)\u001b[0m\n\u001b[1;32m   1288\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m flags \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1289\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1290\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnon-zero flags not allowed in calls to recv() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m   1291\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m)\n\u001b[0;32m-> 1292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbuflen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1293\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mrecv(buflen, flags)\n",
      "File \u001b[0;32m~/anaconda3/envs/python3/lib/python3.10/ssl.py:1165\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[0;34m(self, len, buffer)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sslobj\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m, buffer)\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1165\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m x:\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m SSL_ERROR_EOF \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuppress_ragged_eofs:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for tweet in tweet_data:\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet delimited by {delimiter} in the following steps:\n",
    "                                        step 1 {delimiter} identify the tweet sentiment in a single word, either positive, negative or neutral;\n",
    "                                        step 2 {delimiter} identify the emotions expressed in the tweet with a single word;\n",
    "                                        step 3 {delimiter} extract the mentioned peoples;\n",
    "                                        step 4 {delimiter} detect whether the tweet support Democratic or Replublican, return the resunt in a single word;\n",
    "                                        step 5 {delimiter} organize the result in a json document with the keys <sentiment>, <emontion>,<mentioned>, <support>\n",
    "                                         Do not wrap the json codes in JSON markers and only return the json document\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet}{delimiter} \"}]\n",
    "    print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78c4fb96-a33c-44a0-b754-58efc2972c8a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"1\": \"Generative AI and Art\",\n",
      "  \"2\": \"Ethical Concerns of Generative AI\",\n",
      "  \"3\": \"Generative AI in Business and Innovation\",\n",
      "  \"4\": \"Generative AI and Data Security\",\n",
      "  \"5\": \"Generative AI in Education and Learning\",\n",
      "  \"6\": \"Generative AI in Media and Content Creation\",\n",
      "  \"7\": \"Generative AI and Environmental Impact\",\n",
      "  \"8\": \"Generative AI and Legal Issues\",\n",
      "  \"9\": \"Generative AI and Cultural Impact\",\n",
      "  \"10\": \"Generative AI and Technological Advancements\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet delimited by {delimiter} to identify 10 topics, \n",
    "                                  Do not wrap the json codes in JSON markers \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet_data}{delimiter} \"}]\n",
    "print(openai_help(messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c9e00-9cbb-4f96-a0bf-79135d0c8262",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Expanding with multiple prompts \n",
    "- Identify which party receives majority supports\n",
    "- Provide contexts in the system message\n",
    "- Create a chatbot to answer users’ inquiry  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d34f68d6-2794-452f-9d5a-4b52fac427d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [01:29<00:00,  1.11it/s]\n"
     ]
    }
   ],
   "source": [
    "analysis_result = []\n",
    "from tqdm import tqdm\n",
    "for tweet in tqdm(tweet_data):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet delimited by {delimiter} in the following steps:\n",
    "                                        step 1 {delimiter} identify the tweet sentiment in a single word, either positive, negative or neutral;\n",
    "                                        step 2 {delimiter} identify the emotions expressed in the tweet with a single word;\n",
    "                                        step 3 {delimiter} extract the mentioned peoples;\n",
    "                                        step 4 {delimiter} detect whether the tweet support Democratic or Replublican, return the resunt in a singple word;\n",
    "                                        step 5 {delimiter} organize the result in a json document with the keys <sentiment>, <emontion>,<mentioned>, <support>\n",
    "                                         Do not wrap the json codes in JSON markers and only return the json document\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{tweet}{delimiter} \"}]\n",
    "    analysis_result.append(openai_help(messages))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f564426c-53a9-4415-9d94-790ea68907de",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"redstickynotes\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"jblefevre60\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"disagreement\",\\n  \"mentioned\": [\"NatesManagement\", \"Blavin24\", \"Cedralian\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"HorrorHijabi\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"disapproval\",\\n  \"mentioned\": [\"stupidformo\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"concern\",\\n  \"mentioned\": [\"@le_wokeisme\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"pride\",\\n  \"mentioned\": [\\n    \"@Gartner_inc\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"concern\",\\n  \"mentioned\": [\"WIRED\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"freezetheberry\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"hankgreen\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"jblefevre60\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifferent\",\\n  \"mentioned\": [\"@notasnervous\", \"@TheKnownOtaku\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifferent\",\\n  \"mentioned\": [\"nosgov\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"HorrorHijabi\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"HorrorHijabi\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"anger\",\\n  \"mentioned\": [\\n    \"Chorrozard\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifferent\",\\n  \"mentioned\": [\"@notasnervous\", \"@TheKnownOtaku\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"playful\",\\n  \"mentioned\": [\"16pxl\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"impressed\",\\n  \"mentioned\": [\"@templecrash\", \"@AIWayfinder\", \"@andy8052\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"excitement\",\\n  \"mentioned\": [\"@Hiteshdotcom\", \"@piyushgarg_dev\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"confusion\",\\n  \"mentioned\": [\"@kimmonismus\", \"@grok\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"anticipation\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"excitement\",\\n  \"mentioned\": [\\n    \"DynamicWebPaige\",\\n    \"Kaggle\",\\n    \"GoogleDeepMind\",\\n    \"GoogleCloud\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"excitement\",\\n  \"mentioned\": [\"web3pam\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"excitement\",\\n  \"mentioned\": [\"web3pam\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"frustration\",\\n  \"mentioned\": [\"NonsenseIsland\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\\n    \"Corey Gildart\",\\n    \"@FTITech\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"HorrorHijabi\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifferent\",\\n  \"mentioned\": [\"shark_puffs_\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"amazement\",\\n  \"mentioned\": [\"TimaeusChalamet\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"HorrorHijabi\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"expectation\",\\n  \"mentioned\": [\"@oscpmentor\", \"@vxunderground\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"MoureDev\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"playful\",\\n  \"mentioned\": [\"16pxl\"],\\n  \"support\": \"\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"MoureDev\", \"Microsoft\"],\\n  \"support\": \"\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"anticipation\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"optimism\",\\n  \"mentioned\": [],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"frustration\",\\n  \"mentioned\": [\"@poiyomi\", \"@HOUNDDS\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"curiosity\",\\n  \"mentioned\": [\"sawyomom\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"anger\",\\n  \"mentioned\": [\"Artistreccs\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"jblefevre60\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"excitement\",\\n  \"mentioned\": [\\n    \"AWS\",\\n    \"Samsung\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"thoughtful\",\\n  \"mentioned\": [\\n    \"@Writing_Dragons\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"congratulatory\",\\n  \"mentioned\": [\"@MahojinAI\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"curiosity\",\\n  \"mentioned\": [\"AdrianEarthmeta\"],\\n  \"support\": \"\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"freezetheberry\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"jblefevre60\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"HorrorHijabi\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"enthusiasm\",\\n  \"mentioned\": [\"nvidia\", \"awscloud\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"Brian Adler\", \"Jay Litkey\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"curiosity\",\\n  \"mentioned\": [],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"excitement\",\\n  \"mentioned\": [],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"namazu_sensei\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"playful\",\\n  \"mentioned\": [\"16pxl\"],\\n  \"support\": \"\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"jblefevre60\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\\n    \"CurieuxExplorer\",\\n    \"PawlowskiMario\",\\n    \"mvollmer1\",\\n    \"gvalan\",\\n    \"ipfconline1\",\\n    \"LaurentAlaus\",\\n    \"Shi4Tech\",\\n    \"Fisher85M\",\\n    \"kalydeoo\",\\n    \"Ym78200\",\\n    \"Nicochan33\",\\n    \"Fabriziobustama\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"RedPill_Marxism\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"DiaboIicAngel\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"calm\",\\n  \"mentioned\": [\"chambaz\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"excitement\",\\n  \"mentioned\": [],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"admiration\",\\n  \"mentioned\": [\"@sama\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"concern\",\\n  \"mentioned\": [\"stefanbertin\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"collaborative\",\\n  \"mentioned\": [\"nvidia\", \"awscloud\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"none\",\\n  \"mentioned\": [\"@alx_africa\"],\\n  \"support\": \"none\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"SarvamAI\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"edmundmcmillen\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"concern\",\\n  \"mentioned\": [\"adjudicatorcb\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\\n    \"@CoreOfMidas\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"curiosity\",\\n  \"mentioned\": [\"SenseiBR_btc\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"hopeful\",\\n  \"mentioned\": [\"carolduvallon\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"anticipation\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"HorrorHijabi\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"disdain\",\\n  \"mentioned\": [\"@imzeferino\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"frustration\",\\n  \"mentioned\": [\"Xander_J_C\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"frustration\",\\n  \"mentioned\": [\"@geekshrine\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"hydreamgeas\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"curiosity\",\\n  \"mentioned\": [\"OlivierKamitatu\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"anger\",\\n  \"mentioned\": [\"Artistreccs\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"indifference\",\\n  \"mentioned\": [\"HorrorHijabi\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"admiration\",\\n  \"mentioned\": [\"@iamn3el\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"@CEBass_writer\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"anger\",\\n  \"mentioned\": [\"Artistreccs\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"GeorgeCrudo\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"none\",\\n  \"mentioned\": [],\\n  \"support\": \"none\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"anger\",\\n  \"mentioned\": [\"Artistreccs\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"MoureDev\", \"Microsoft\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"runwayml\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"informative\",\\n  \"mentioned\": [\"paul mccartney\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"concern\",\\n  \"mentioned\": [\\n    \"GreenTieOffici1\",\\n    \"PiperistheNewbl\",\\n    \"merururuu\"\\n  ],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"positive\",\\n  \"emotion\": \"inspired\",\\n  \"mentioned\": [\"AWSstartups\", \"QodoAI\"],\\n  \"support\": \"neutral\"\\n}', '{\\n  \"sentiment\": \"neutral\",\\n  \"emotion\": \"none\",\\n  \"mentioned\": [\"AlhujiliTurki\"],\\n  \"support\": \"none\"\\n}', '{\\n  \"sentiment\": \"negative\",\\n  \"emotion\": \"disdain\",\\n  \"mentioned\": [\"@VanCommunist\", \"@InfraHaz\"],\\n  \"support\": \"neutral\"\\n}']\n"
     ]
    }
   ],
   "source": [
    "print(analysis_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c601722e-7f37-45fb-b580-9aeed74fe3a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"Democratic count\": 0,\n",
      "  \"Republican count\": 0,\n",
      "  \"people name\": {\n",
      "    \"redstickynotes\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifference\"]\n",
      "    },\n",
      "    \"jblefevre60\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"NatesManagement\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"disagreement\"]\n",
      "    },\n",
      "    \"Blavin24\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"disagreement\"]\n",
      "    },\n",
      "    \"Cedralian\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"disagreement\"]\n",
      "    },\n",
      "    \"HorrorHijabi\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifference\"]\n",
      "    },\n",
      "    \"stupidformo\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"disapproval\"]\n",
      "    },\n",
      "    \"@le_wokeisme\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"concern\"]\n",
      "    },\n",
      "    \"@Gartner_inc\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"pride\"]\n",
      "    },\n",
      "    \"WIRED\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"concern\"]\n",
      "    },\n",
      "    \"freezetheberry\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifference\"]\n",
      "    },\n",
      "    \"hankgreen\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"@notasnervous\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifferent\"]\n",
      "    },\n",
      "    \"@TheKnownOtaku\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifferent\"]\n",
      "    },\n",
      "    \"nosgov\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifferent\"]\n",
      "    },\n",
      "    \"Chorrozard\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"anger\"]\n",
      "    },\n",
      "    \"16pxl\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"playful\"]\n",
      "    },\n",
      "    \"@templecrash\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"impressed\"]\n",
      "    },\n",
      "    \"@AIWayfinder\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"impressed\"]\n",
      "    },\n",
      "    \"@andy8052\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"impressed\"]\n",
      "    },\n",
      "    \"@Hiteshdotcom\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"excitement\"]\n",
      "    },\n",
      "    \"@piyushgarg_dev\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"excitement\"]\n",
      "    },\n",
      "    \"@kimmonismus\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"confusion\"]\n",
      "    },\n",
      "    \"@grok\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"confusion\"]\n",
      "    },\n",
      "    \"runwayml\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"anticipation\", \"informative\"]\n",
      "    },\n",
      "    \"DynamicWebPaige\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"excitement\"]\n",
      "    },\n",
      "    \"Kaggle\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"excitement\"]\n",
      "    },\n",
      "    \"GoogleDeepMind\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"excitement\"]\n",
      "    },\n",
      "    \"GoogleCloud\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"excitement\"]\n",
      "    },\n",
      "    \"web3pam\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"excitement\"]\n",
      "    },\n",
      "    \"NonsenseIsland\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"frustration\"]\n",
      "    },\n",
      "    \"Corey Gildart\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"@FTITech\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"shark_puffs_\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifferent\"]\n",
      "    },\n",
      "    \"TimaeusChalamet\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"amazement\"]\n",
      "    },\n",
      "    \"@oscpmentor\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"expectation\"]\n",
      "    },\n",
      "    \"@vxunderground\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"expectation\"]\n",
      "    },\n",
      "    \"MoureDev\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"Microsoft\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"@poiyomi\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"frustration\"]\n",
      "    },\n",
      "    \"@HOUNDDS\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"frustration\"]\n",
      "    },\n",
      "    \"sawyomom\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"curiosity\"]\n",
      "    },\n",
      "    \"Artistreccs\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"anger\"]\n",
      "    },\n",
      "    \"Brian Adler\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"Jay Litkey\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"@Writing_Dragons\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"thoughtful\"]\n",
      "    },\n",
      "    \"@MahojinAI\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"congratulatory\"]\n",
      "    },\n",
      "    \"AdrianEarthmeta\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"curiosity\"]\n",
      "    },\n",
      "    \"RedPill_Marxism\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifference\"]\n",
      "    },\n",
      "    \"DiaboIicAngel\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"chambaz\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"calm\"]\n",
      "    },\n",
      "    \"@sama\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"admiration\"]\n",
      "    },\n",
      "    \"stefanbertin\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"concern\"]\n",
      "    },\n",
      "    \"nvidia\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"enthusiasm\", \"collaborative\"]\n",
      "    },\n",
      "    \"awscloud\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"enthusiasm\", \"collaborative\"]\n",
      "    },\n",
      "    \"@alx_africa\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"none\"]\n",
      "    },\n",
      "    \"SarvamAI\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"edmundmcmillen\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifference\"]\n",
      "    },\n",
      "    \"adjudicatorcb\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"concern\"]\n",
      "    },\n",
      "    \"@CoreOfMidas\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"SenseiBR_btc\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"curiosity\"]\n",
      "    },\n",
      "    \"carolduvallon\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"hopeful\"]\n",
      "    },\n",
      "    \"@imzeferino\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"disdain\"]\n",
      "    },\n",
      "    \"Xander_J_C\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"frustration\"]\n",
      "    },\n",
      "    \"@geekshrine\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"frustration\"]\n",
      "    },\n",
      "    \"hydreamgeas\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"indifference\"]\n",
      "    },\n",
      "    \"OlivierKamitatu\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"curiosity\"]\n",
      "    },\n",
      "    \"@iamn3el\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"admiration\"]\n",
      "    },\n",
      "    \"@CEBass_writer\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"GeorgeCrudo\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"paul mccartney\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"informative\"]\n",
      "    },\n",
      "    \"GreenTieOffici1\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"concern\"]\n",
      "    },\n",
      "    \"PiperistheNewbl\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"concern\"]\n",
      "    },\n",
      "    \"merururuu\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"concern\"]\n",
      "    },\n",
      "    \"AWSstartups\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"inspired\"]\n",
      "    },\n",
      "    \"QodoAI\": {\n",
      "      \"sentiments\": [\"positive\"],\n",
      "      \"emotions\": [\"inspired\"]\n",
      "    },\n",
      "    \"AlhujiliTurki\": {\n",
      "      \"sentiments\": [\"neutral\"],\n",
      "      \"emotions\": [\"none\"]\n",
      "    },\n",
      "    \"@VanCommunist\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"disdain\"]\n",
      "    },\n",
      "    \"@InfraHaz\": {\n",
      "      \"sentiments\": [\"negative\"],\n",
      "      \"emotions\": [\"disdain\"]\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "        {\"role\": \"system\", \"content\": f\"\"\"analyze the tweet analysis reuslt delimited by {delimiter} in the following steps:\n",
    "                                        step 1 {delimiter} count the number of tweets that support Democratic and Republican;\n",
    "                                        step 2 {delimiter} identify the common sentiments and emotoions to each mentioned people;\n",
    "                                        step 3 {delimiter} organize the result in a json document with keys <Democratic count>, <Republican count>, <people name>\n",
    "                                         Do not wrap the json codes in JSON markers and only return the json document\"\"\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{delimiter}{analysis_result}{delimiter} \"}]\n",
    "analysis_summary = openai_help(messages)\n",
    "print(analysis_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5f98ac-b2f6-4741-82c9-8e8f88f09cf1",
   "metadata": {},
   "source": [
    "## Create a chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "91173534-53b8-4d6b-b9c0-198913b7ada8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "openai_api_key  = get_secret('openai')['api_key']\n",
    "client = OpenAI(api_key=openai_api_key)\n",
    "model = 'gpt-4o'\n",
    "temperature = 0\n",
    "\n",
    "chat_history = [\n",
    "\n",
    "{\"role\": \"system\", \"content\": f\"\"\"you are a chabot answer user questions based on the tweets,\n",
    "                                {delimiter}{tweet_data}{delimiter}, \n",
    "                                if user mentioned a people name in the {delimiter}{analysis_summary}{delimiter} people field,report the corresponding sentiment and emotion,\n",
    "                            \n",
    "                            \"\"\"}\n",
    "]\n",
    "\n",
    "def chatbot(prompt):\n",
    "\n",
    "    chat_history.append({\"role\": \"user\", \"content\": prompt})\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,  # Use the model you prefer\n",
    "        messages=chat_history\n",
    "    )\n",
    "\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    \n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a949601-5af9-4d0b-80d7-5297cc4e52f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "    if user_input.lower() in ['exit', 'quit']:\n",
    "        print(\"Chatbot: Goodbye!\")\n",
    "        break\n",
    "    reply = chatbot(user_input)\n",
    "    print(f\"Chatbot: {reply}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f497dd9-8e6e-4f40-b546-8fe225185729",
   "metadata": {},
   "source": [
    "## Reference\n",
    "- Isa Fulford and Andrew Ng. n.d.-a. *“Building Systems with the ChatGPT API.”* DeepLearning.AI. Accessed October 25, 2024. https://www.deeplearning.ai/short-courses/building-systems-with-chatgpt/.\n",
    "- ———. n.d.-b. *“ChatGPT Prompt Engineering for Developers.”* DeepLearning.AI. Accessed October 25, 2024. https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/.\n",
    "- OpenAI. n.d. *“OpenAI Documents.”* OpenAI. Accessed October 18, 2024. https://platform.openai.com.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b06a39-30aa-498b-aff2-049fd65b7fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
